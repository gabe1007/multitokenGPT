{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T22:22:12.469155Z","iopub.status.busy":"2024-09-23T22:22:12.468851Z","iopub.status.idle":"2024-09-23T22:22:16.757293Z","shell.execute_reply":"2024-09-23T22:22:16.756093Z","shell.execute_reply.started":"2024-09-23T22:22:12.469126Z"},"trusted":true},"outputs":[],"source":["# Common imports \n","import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T22:22:31.086013Z","iopub.status.busy":"2024-09-23T22:22:31.085632Z","iopub.status.idle":"2024-09-23T22:22:31.127161Z","shell.execute_reply":"2024-09-23T22:22:31.125868Z","shell.execute_reply.started":"2024-09-23T22:22:31.085984Z"},"trusted":true},"outputs":[],"source":["# Necessary hyperparameters\n","\n","BATCH_SIZE = 128\n","BLOCK_SIZE = 256 \n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","N_EMBED = 256\n","N_HEADS = 4\n","DROPOUT = 0.2\n","N_LAYER = 5\n","LEARNING_RATE = 3e-3\n","MAX_ITERS = 10000\n","EVAL_INTERVAL = 500\n","EVAL_ITERS = 200"]},{"cell_type":"markdown","metadata":{},"source":["#### Dataset, encoder and decoder creation and datasplits"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T22:22:31.691593Z","iopub.status.busy":"2024-09-23T22:22:31.690888Z","iopub.status.idle":"2024-09-23T22:22:33.082266Z","shell.execute_reply":"2024-09-23T22:22:33.081158Z","shell.execute_reply.started":"2024-09-23T22:22:31.691558Z"},"trusted":true},"outputs":[],"source":["# Just add the local dataset path\n","with open('./40k.txt', 'r', encoding='utf-8') as f:\n","    text = f.read()\n","\n","# Unique characters that occur in this text\n","chars = sorted(list(set(text)))\n","VOCAB_SIZE = len(chars)\n","\n","# Map the characters\n","stoi = { ch:i for i,ch in enumerate(chars) }\n","itos = { i:ch for i,ch in enumerate(chars) }\n","encode = lambda s: [stoi[c] for c in s]\n","decode = lambda l: ''.join([itos[i] for i in l]) \n","\n","# Get data splits\n","data = torch.tensor(encode(text), dtype=torch.long)\n","n = int(0.9*len(data)) \n","train = data[:n]\n","val = data[n:]"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T22:22:33.084596Z","iopub.status.busy":"2024-09-23T22:22:33.084228Z","iopub.status.idle":"2024-09-23T22:22:33.092150Z","shell.execute_reply":"2024-09-23T22:22:33.091091Z","shell.execute_reply.started":"2024-09-23T22:22:33.084549Z"},"trusted":true},"outputs":[],"source":["def get_batch(split, n_pred_tokens=4):\n","    \"\"\"\n","    Generate a small batch of data for training or validation.\n","\n","    Parameters:\n","    split (str): The dataset split to use, either 'train' or 'val'.\n","    n_pred_tokens (int): The number of future tokens to predict. Default is 4.\n","    \"\"\"\n","    data = train if split == 'train' else val\n","    ix = torch.randint(len(data) - BLOCK_SIZE - n_pred_tokens + 1, (BATCH_SIZE,))\n","    x = torch.stack([data[i:i + BLOCK_SIZE] for i in ix])\n","    y = torch.stack([data[i+1:i + BLOCK_SIZE + n_pred_tokens] for i in ix])\n","    x, y = x.to(DEVICE), y.to(DEVICE)\n","    \n","    return x, y"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T22:22:33.093805Z","iopub.status.busy":"2024-09-23T22:22:33.093439Z","iopub.status.idle":"2024-09-23T22:22:33.101902Z","shell.execute_reply":"2024-09-23T22:22:33.100815Z","shell.execute_reply.started":"2024-09-23T22:22:33.093776Z"},"trusted":true},"outputs":[],"source":["@torch.no_grad()\n","def estimate_loss():\n","    \"\"\"\n","    Estimate the loss for both training and validation datasets.\n","\n","    This function evaluates the model in evaluation mode to estimate the loss\n","    without updating the model parameters. It calculates the average loss over\n","    a number of evaluation iterations for both the training and validation splits.\n","\n","    Returns:\n","    dict: A dictionary containing the average loss for 'train' and 'val' splits.\n","    \"\"\"\n","    out = {}\n","    model.eval()  # Set the model to evaluation mode\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(EVAL_ITERS)\n","        for k in range(EVAL_ITERS):\n","            X, Y = get_batch(split)\n","            logits, loss = model(X, Y) \n","            losses[k] = loss.item()\n","        out[split] = losses.mean()\n","    model.train()\n","    return out"]},{"cell_type":"markdown","metadata":{},"source":["#### Attention block"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T22:22:33.372171Z","iopub.status.busy":"2024-09-23T22:22:33.371264Z","iopub.status.idle":"2024-09-23T22:22:33.392819Z","shell.execute_reply":"2024-09-23T22:22:33.391425Z","shell.execute_reply.started":"2024-09-23T22:22:33.372136Z"},"trusted":true},"outputs":[],"source":["class Head(nn.Module):\n","    \"\"\" one head of self-attention \"\"\"\n","\n","    def __init__(self, head_size):\n","        super().__init__()\n","        self.key = nn.Linear(N_EMBED, head_size, bias=False) # head_size x N_EMBED\n","        self.query = nn.Linear(N_EMBED, head_size, bias=False)\n","        self.value = nn.Linear(N_EMBED, head_size, bias=False)\n","        self.register_buffer('tril', torch.tril(torch.ones(BLOCK_SIZE, BLOCK_SIZE)))\n","\n","        self.dropout = nn.Dropout(DROPOUT)\n","\n","    def forward(self, x):\n","        # input of size (B, T, C)\n","        # output of size (B, T, head_size)\n","        B,T,C = x.shape\n","        #  x = B,T,C = 16, 256, 512,  self.key = 64 x 512, linear performs xAT+b,\n","        # since nn.Linear inverts the order we have to transpose self.key to get 16 x 256 x 512 @ 512 x 64\n","        k = self.key(x)\n","        q = self.query(x) # (B,T,hs)\n","        # compute attention scores (\"affinities\")\n","        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n","        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n","        wei = F.softmax(wei, dim=-1) # (B, T, T) dim=-1 means that the softmax function is applied along the last dimension of the tensor.\n","        wei = self.dropout(wei)\n","        # perform the weighted aggregation of the values\n","        v = self.value(x) # (B,T,hs)\n","        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n","        return out\n","\n","class MultiHeadAttention(nn.Module):\n","    \"\"\" multiple heads of self-attention in parallel \"\"\"\n","\n","    def __init__(self, num_heads, head_size):\n","        super().__init__()\n","        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","        self.proj = nn.Linear(head_size * num_heads, N_EMBED) # 512 x 512\n","        self.dropout = nn.Dropout(DROPOUT)\n","\n","    def forward(self, x):\n","        out = torch.cat([h(x) for h in self.heads], dim=-1)\n","        out = self.dropout(self.proj(out))\n","        return out\n","\n","class FeedFoward(nn.Module):\n","    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n","\n","    def __init__(self, n_embd):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(n_embd, 4 * n_embd),\n","            nn.ReLU(),\n","            nn.Linear(4 * n_embd, n_embd),\n","            nn.Dropout(DROPOUT),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Block(nn.Module):\n","    \"\"\" Transformer block: communication followed by computation \"\"\"\n","\n","    def __init__(self, n_embd, n_head):\n","        # n_embd: embedding dimension, n_head: the number of heads we'd like\n","        super().__init__()\n","        head_size = n_embd // n_head\n","        self.sa = MultiHeadAttention(n_head, head_size)\n","        self.ffwd = FeedFoward(n_embd)\n","        self.ln1 = nn.LayerNorm(n_embd)\n","        self.ln2 = nn.LayerNorm(n_embd)\n","\n","    def forward(self, x):\n","        x = x + self.sa(self.ln1(x))\n","        x = x + self.ffwd(self.ln2(x))\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["#### Transformers blocks"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T22:39:36.024685Z","iopub.status.busy":"2024-09-23T22:39:36.023813Z","iopub.status.idle":"2024-09-23T22:39:36.043108Z","shell.execute_reply":"2024-09-23T22:39:36.042037Z","shell.execute_reply.started":"2024-09-23T22:39:36.024649Z"},"trusted":true},"outputs":[],"source":["class GPTLanguageModel(nn.Module):\n","    def __init__(self, num_pred_tokens=4):  \n","        super().__init__()\n","        self.num_pred_tokens = num_pred_tokens\n","        self.token_embedding_table = nn.Embedding(VOCAB_SIZE, N_EMBED)\n","        self.position_embedding_table = nn.Embedding(BLOCK_SIZE, N_EMBED)\n","        self.blocks = nn.Sequential(*[Block(N_EMBED, n_head=N_HEADS) for _ in range(N_LAYER)])\n","        self.ln_f = nn.LayerNorm(N_EMBED)\n","        self.lm_heads = nn.ModuleList([nn.Linear(N_EMBED, VOCAB_SIZE) for _ in range(num_pred_tokens)])\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","            if module.bias is not None:\n","                torch.nn.init.zeros_(module.bias)\n","        elif isinstance(module, nn.Embedding):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","\n","    def forward(self, idx, targets=None):\n","        B, T = idx.shape\n","        # Token and position embeddings\n","        tok_emb = self.token_embedding_table(idx)  # (B, T, C)\n","        pos_emb = self.position_embedding_table(torch.arange(T, device=DEVICE))  # (T, C)\n","        x = tok_emb + pos_emb  # (B, T, C)\n","        x = self.blocks(x)  # (B, T, C)\n","        x = self.ln_f(x)  # (B, T, C)\n","        \n","        # Apply each head\n","        logits = [head(x) for head in self.lm_heads]\n","        logits = torch.stack(logits, dim=2)  # Stack over the num_pred_tokens dimension: (B, T, num_pred_tokens, vocab_size)\n","        \n","        if targets is None:\n","            loss = None\n","        else: \n","            B, T, N, C = logits.shape\n","            losses = []\n","            for i in range(N):\n","                head_logits = logits[:, :, i, :].reshape(B * T, C)\n","                head_targets = targets[:, i:i + T].reshape(B * T) \n","                losses.append(F.cross_entropy(head_logits, head_targets))\n","            loss = torch.mean(torch.stack(losses))\n","        return logits, loss\n","    \n","    def generate(self, idx, max_new_tokens):\n","        # idx is (B, T) array of indices in the current context\n","        for _ in range(max_new_tokens):\n","            # crop idx to the last block_size tokens\n","            idx_cond = idx[:, -BLOCK_SIZE:]\n","\n","            # get the predictions (logits from the first head only)\n","            logits, _ = self(idx_cond)  # logits: (B, T, num_pred_tokens, vocab_size)\n","\n","            # Use only the first head for token generation\n","            logits_head = logits[:, -1, 0, :]  # (B, vocab_size)\n","\n","            # Apply softmax to get probabilities for the next token\n","            probs = F.softmax(logits_head, dim=-1)  # (B, vocab_size)\n","\n","            # Sample from the distribution for the next token\n","            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n","\n","            # Append the sampled token to the running sequence\n","            idx = torch.cat((idx, idx_next), dim=1)  # (B, T + 1)\n","\n","        return idx"]},{"cell_type":"markdown","metadata":{},"source":["#### Functions to save and reload the trainned model"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T22:22:35.495451Z","iopub.status.busy":"2024-09-23T22:22:35.494481Z","iopub.status.idle":"2024-09-23T22:22:35.502066Z","shell.execute_reply":"2024-09-23T22:22:35.500954Z","shell.execute_reply.started":"2024-09-23T22:22:35.495417Z"},"trusted":true},"outputs":[],"source":["def save_checkpoint(model, optimizer, filename=\"model.pth\"):\n","    checkpoint = {\n","        \"model_state_dict\": model.state_dict(),\n","        \"optimizer_state_dict\": optimizer.state_dict(),\n","    }\n","    torch.save(checkpoint, filename)\n","    \n","    \n","def load_checkpoint(model, optimizer, filename=\"model.pth\"):\n","    checkpoint = torch.load(filename)\n","    model.load_state_dict(checkpoint[\"model_state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n","    return model, optimizer"]},{"cell_type":"markdown","metadata":{},"source":["#### Trainning loop"]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2024-09-21T23:13:53.006399Z","iopub.status.busy":"2024-09-21T23:13:53.005808Z","iopub.status.idle":"2024-09-22T01:22:45.272445Z","shell.execute_reply":"2024-09-22T01:22:45.271367Z","shell.execute_reply.started":"2024-09-21T23:13:53.006366Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["4.131704 M parameters\n","step 0: train loss 4.5979, val loss 4.5989\n","step 500: train loss 2.6752, val loss 2.7004\n","step 1000: train loss 2.3533, val loss 2.3999\n","step 1500: train loss 2.1757, val loss 2.2367\n","step 2000: train loss 2.0959, val loss 2.1594\n","step 2500: train loss 2.0519, val loss 2.1288\n","step 3000: train loss 2.0194, val loss 2.0969\n","step 3500: train loss 1.9993, val loss 2.0843\n","step 4000: train loss 1.9808, val loss 2.0644\n","step 4500: train loss 1.9678, val loss 2.0588\n","step 5000: train loss 1.9527, val loss 2.0475\n","step 5500: train loss 1.9457, val loss 2.0369\n","step 6000: train loss 1.9378, val loss 2.0340\n","step 6500: train loss 1.9282, val loss 2.0293\n","step 7000: train loss 1.9215, val loss 2.0268\n","step 7500: train loss 1.9168, val loss 2.0227\n","step 8000: train loss 1.9083, val loss 2.0175\n","step 8500: train loss 1.9085, val loss 2.0212\n","step 9000: train loss 1.8992, val loss 2.0119\n","step 9500: train loss 1.8955, val loss 2.0107\n","step 10000: train loss 1.8915, val loss 2.0072\n","step 10500: train loss 1.8872, val loss 2.0068\n","step 11000: train loss 1.8840, val loss 2.0043\n","step 11500: train loss 1.8784, val loss 1.9997\n","step 12000: train loss 1.8771, val loss 2.0017\n","step 12500: train loss 1.8712, val loss 1.9952\n","step 13000: train loss 1.8694, val loss 1.9987\n","step 13500: train loss 1.8711, val loss 1.9966\n","step 14000: train loss 1.8657, val loss 1.9954\n","step 14500: train loss 1.8622, val loss 1.9917\n","step 15000: train loss 1.8624, val loss 1.9909\n","step 15500: train loss 1.8575, val loss 1.9931\n","step 16000: train loss 1.8553, val loss 1.9944\n","step 16500: train loss 1.8556, val loss 1.9894\n","step 17000: train loss 1.8527, val loss 1.9929\n","step 17500: train loss 1.8493, val loss 1.9843\n","step 18000: train loss 1.8463, val loss 1.9876\n","step 18500: train loss 1.8444, val loss 1.9798\n","step 19000: train loss 1.8414, val loss 1.9863\n","step 19500: train loss 1.8414, val loss 1.9845\n","step 20000: train loss 1.8408, val loss 1.9817\n","step 20500: train loss 1.8411, val loss 1.9852\n","step 21000: train loss 1.8358, val loss 1.9766\n","step 21500: train loss 1.8374, val loss 1.9790\n","step 22000: train loss 1.8331, val loss 1.9788\n","step 22500: train loss 1.8334, val loss 1.9821\n","step 23000: train loss 1.8298, val loss 1.9771\n","step 23500: train loss 1.8282, val loss 1.9761\n","step 24000: train loss 1.8286, val loss 1.9748\n","step 24500: train loss 1.8288, val loss 1.9855\n","step 24999: train loss 1.8292, val loss 1.9830\n"]}],"source":["model = GPTLanguageModel()\n","m = model.to(DEVICE)\n","\n","# print the number of parameters in the model\n","print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n","\n","# create a PyTorch optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE)\n","\n","for iter in range(MAX_ITERS):\n","\n","    # every once in a while evaluate the loss on train and val sets\n","    if iter % EVAL_INTERVAL == 0 or iter == MAX_ITERS - 1:\n","        losses = estimate_loss()\n","        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","    # sample a batch of data\n","    xb, yb = get_batch('train')\n","\n","    # evaluate the loss\n","    logits, loss = model(xb, yb)\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    optimizer.step()"]},{"cell_type":"markdown","metadata":{},"source":["We got a pretty decent loss. This model was trainned for 50000 iterations, we could have trainned it more, however, it was taking longer and longer to decrease the trainning loss so i decided the stop trainning and check out the results. \n","\n","We i trainned the vanilla model, it was trainned with the same 50000 iters but we got a loss of approximately 1.20. It was a smaller loss however it does not mean a better result. We are going to confirm this latter.  "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Save the model after the training loop\n","save_checkpoint(model, optimizer, filename=\"multitoken_40k_40000.pth\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Load the model for further trainning \n","\n","As mentioned above, the model was trainned for 50000 iters, but we did not do this trainning all at once as the model was trainned on Kaggle."]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T22:39:42.023170Z","iopub.status.busy":"2024-09-23T22:39:42.022314Z","iopub.status.idle":"2024-09-23T22:39:42.317108Z","shell.execute_reply":"2024-09-23T22:39:42.316221Z","shell.execute_reply.started":"2024-09-23T22:39:42.023136Z"},"trusted":true},"outputs":[{"data":{"text/plain":["GPTLanguageModel(\n","  (token_embedding_table): Embedding(94, 256)\n","  (position_embedding_table): Embedding(256, 256)\n","  (blocks): Sequential(\n","    (0): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-3): 4 x Head(\n","            (key): Linear(in_features=256, out_features=64, bias=False)\n","            (query): Linear(in_features=256, out_features=64, bias=False)\n","            (value): Linear(in_features=256, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=256, out_features=256, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=256, out_features=1024, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=1024, out_features=256, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (1): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-3): 4 x Head(\n","            (key): Linear(in_features=256, out_features=64, bias=False)\n","            (query): Linear(in_features=256, out_features=64, bias=False)\n","            (value): Linear(in_features=256, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=256, out_features=256, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=256, out_features=1024, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=1024, out_features=256, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (2): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-3): 4 x Head(\n","            (key): Linear(in_features=256, out_features=64, bias=False)\n","            (query): Linear(in_features=256, out_features=64, bias=False)\n","            (value): Linear(in_features=256, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=256, out_features=256, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=256, out_features=1024, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=1024, out_features=256, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (3): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-3): 4 x Head(\n","            (key): Linear(in_features=256, out_features=64, bias=False)\n","            (query): Linear(in_features=256, out_features=64, bias=False)\n","            (value): Linear(in_features=256, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=256, out_features=256, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=256, out_features=1024, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=1024, out_features=256, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (4): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-3): 4 x Head(\n","            (key): Linear(in_features=256, out_features=64, bias=False)\n","            (query): Linear(in_features=256, out_features=64, bias=False)\n","            (value): Linear(in_features=256, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=256, out_features=256, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=256, out_features=1024, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=1024, out_features=256, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","  (lm_heads): ModuleList(\n","    (0-3): 4 x Linear(in_features=256, out_features=94, bias=True)\n","  )\n",")"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["# This cell loads the model again for further trainning \n","\n","model = GPTLanguageModel()\n","checkpoint = torch.load(\"/kaggle/input/multitoken_30000/pytorch/default/1/multitoken_40k_30000.pth\", map_location=DEVICE)\n","model.load_state_dict(checkpoint['model_state_dict'])\n","# Move the model to the desired device\n","model.to(DEVICE)\n","\n","# Recreate the optimizer after moving the model to the desired device\n","optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","# Move optimizer state to the same device as model\n","for state in optimizer.state.values():\n","    for k, v in state.items():\n","        if isinstance(v, torch.Tensor):\n","            state[k] = v.to(DEVICE)\n","\n","# Set the model to training mode\n","model.train()  # Important for training"]},{"cell_type":"markdown","metadata":{},"source":["#### Separate trainning loop."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for iter in range(MAX_ITERS):\n","\n","    if iter % EVAL_INTERVAL == 0 or iter == MAX_ITERS - 1:\n","        losses = estimate_loss()\n","        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","    xb, yb = get_batch('train')\n","\n","    logits, loss = model(xb, yb)\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    optimizer.step()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save the model\n","save_checkpoint(model, optimizer, filename=\"multitoken_40k_50000.pth\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Inference code\n","\n","The inference was made on a cpu because i do not have a GPU, that's what the parameter **map_location=torch.device('cpu')** is for. If you have a GPU, delete this parameter. "]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T22:39:54.910884Z","iopub.status.busy":"2024-09-23T22:39:54.910521Z","iopub.status.idle":"2024-09-23T22:39:55.183548Z","shell.execute_reply":"2024-09-23T22:39:55.182386Z","shell.execute_reply.started":"2024-09-23T22:39:54.910858Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_5317/3786466031.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(\"./multitoken_40k_50000.pth\", map_location=torch.device('cpu'))\n"]},{"data":{"text/plain":["GPTLanguageModel(\n","  (token_embedding_table): Embedding(94, 256)\n","  (position_embedding_table): Embedding(256, 256)\n","  (blocks): Sequential(\n","    (0): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-3): 4 x Head(\n","            (key): Linear(in_features=256, out_features=64, bias=False)\n","            (query): Linear(in_features=256, out_features=64, bias=False)\n","            (value): Linear(in_features=256, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=256, out_features=256, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=256, out_features=1024, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=1024, out_features=256, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (1): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-3): 4 x Head(\n","            (key): Linear(in_features=256, out_features=64, bias=False)\n","            (query): Linear(in_features=256, out_features=64, bias=False)\n","            (value): Linear(in_features=256, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=256, out_features=256, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=256, out_features=1024, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=1024, out_features=256, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (2): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-3): 4 x Head(\n","            (key): Linear(in_features=256, out_features=64, bias=False)\n","            (query): Linear(in_features=256, out_features=64, bias=False)\n","            (value): Linear(in_features=256, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=256, out_features=256, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=256, out_features=1024, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=1024, out_features=256, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (3): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-3): 4 x Head(\n","            (key): Linear(in_features=256, out_features=64, bias=False)\n","            (query): Linear(in_features=256, out_features=64, bias=False)\n","            (value): Linear(in_features=256, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=256, out_features=256, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=256, out_features=1024, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=1024, out_features=256, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (4): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-3): 4 x Head(\n","            (key): Linear(in_features=256, out_features=64, bias=False)\n","            (query): Linear(in_features=256, out_features=64, bias=False)\n","            (value): Linear(in_features=256, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=256, out_features=256, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=256, out_features=1024, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=1024, out_features=256, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","  (lm_heads): ModuleList(\n","    (0-3): 4 x Linear(in_features=256, out_features=94, bias=True)\n","  )\n",")"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Load the model for inference\n","model = GPTLanguageModel()\n","optimizer = torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE)\n","\n","# Load the saved model and optimizer\n","checkpoint = torch.load(\"./multitoken_40k_50000.pth\", map_location=torch.device('cpu'))\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","# Move the model to the desired device\n","model.to(DEVICE)\n","\n","# Set the model to eval mode\n","model.eval()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T22:39:56.662948Z","iopub.status.busy":"2024-09-23T22:39:56.661945Z","iopub.status.idle":"2024-09-23T22:40:06.969412Z","shell.execute_reply":"2024-09-23T22:40:06.968255Z","shell.execute_reply.started":"2024-09-23T22:39:56.662914Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","He fell forward – Kircher – the multi-crosses—delighted, blurring\n","across the far side of the line, gracking him in the sterm-seeded hill. He\n","tossed back the floor into his helm, put the others with gone more than his\n","rising fumes. Y’s cramping hidden pieces of drop-pods, defanding. Though\n","that had once been an embers of a nearspace chamber, Octavia’s skull devasivated, he\n","required a perfectly tasked acting screen and trying to jump once more, for\n","the first time he had left to advance. A kilometr\n"]}],"source":["# generate from the model\n","context = torch.zeros((1, 1), dtype=torch.long, device = DEVICE)\n","print(decode(model.generate(context, max_new_tokens=500)[0].tolist()))\n","#open('more.txt', 'w').write(decode(m.generate(context, max_new_tokens=10000)[0].tolist()))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5539335,"sourceId":9167353,"sourceType":"datasetVersion"},{"datasetId":5755681,"sourceId":9465964,"sourceType":"datasetVersion"},{"modelId":102274,"modelInstanceId":77646,"sourceId":92598,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelId":124091,"modelInstanceId":99918,"sourceId":118816,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"decoder","language":"python","name":"decoder"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
